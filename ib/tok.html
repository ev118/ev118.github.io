<!DOCTYPE html>
<html>

<head>
  <title>TOK Essay</title>
  <link rel="stylesheet" href="ib.css" type="text/css" />
</head>

<body>
  <h1>To what extent do you agree with the claim &ldquo;all models are wrong, but some are useful&rdquo; (attributed to
    George Box)?</h1>
  <h3>IB Theory of Knowledge <br> 6 March 2025</h3>

  <p class="noindent">
    In my DP Chemistry studies, we have discussed energetics, the theory that describes the relationship between energy
    and chemical changes. The common trend among concepts in this topic is taking a complex process and simplifying it
    to a number. The tables of these numbers in the data booklet, therefore, are models of the theory of energetics.
    This is a common pattern in the natural sciences, mathematics, and beyond; these fields make extensive use of
    models&mdash;paradigms constructed in order to reduce something complicated to a simpler form. As George Box
    correctly
    noted, something must be lost in the reduction from reality to model, meaning any model must be
    wrong&mdash;incomplete or
    otherwise flawed in a way that makes it inaccurate on the whole. However, despite their drawbacks, many can still be
    useful, due to the increased comprehensibility derived from the process of modelling.
  </p>
  <p>
    The tables in the chemistry data booklet are reference, or literature, values&mdash;the &ldquo;right&rdquo; numbers
    as opposed to
    whatever we might deduce from our own experiments&mdash;and we treat them as always correct. However, these are
    defined
    only for standard conditions and might be different under different conditions. Bond enthalpy, the energy required
    to break a bond, in particular is known to be only an average value because a bond between the same two atoms will
    behave differently in every different compound in which it is found. The notion of such a &ldquo;literature
    value&rdquo; for
    bond enthalpy is a model within chemistry, and though it is &ldquo;wrong&rdquo; in this way it is still useful to
    chemists and
    chemistry students as a point of comparison for experiments.
  </p>
  <br>
  <p>
    Another well-known model in the natural sciences, at the edge of modern physics, is the Standard Model. This is the
    theory that seeks to construct physics, up from the smallest things in the Universe to everything we observe, from
    eighteen fundamental particles. It breaks down matter even further than atoms, into six &ldquo;flavors&rdquo; of
    quarks, which
    make up particles like protons and neutrons; six leptons, which include electrons; and six bosons, which are
    responsible for the forces by which the others interact and for giving them all mass. Since the groundwork was laid
    for quantum physics in the 1890s, and increasingly since the Standard Model was fully theorized in the 1970s,
    hundreds of experiments have confirmed the behaviors that it predicts, and these experiments have helped physicists
    continue to build and refine the theory during that time. Recently, the discoveries of quantum physicists have also
    been contributing to the growing field of quantum computing, which promises to revolutionize information technology
    with previously-unknown computing power.
  </p>
  <p>
    The Standard Model is not, however, without its shortcomings: many of the major open questions in physics revolve
    around its holes. Notably, it does not explain &ldquo;dark matter&rdquo; or &ldquo;dark energy,&rdquo; which
    together are believed to make
    up about 95% of the Universe, and it is irreconcilable with Einstein&rsquo;s general theory of relativity and thus
    the
    modern theory of gravity. The existence of the Higgs boson was also not confirmed until 2012, and even now many of
    its properties are somewhat contentious. Despite these apparently significant gaps, the Standard Model has thus far
    done a very good job of predicting and, to some extent, explaining the results of various experiments in quantum
    physics and beyond. It could be argued that it is &ldquo;wrong&rdquo; because of what it fails to explain, but then
    most laws
    and theories in physics only work in certain conditions; the Standard Model is remarkably useful because it provides
    a framework for describing what classical physics long struggled to (and still cannot) make sense of.
  </p>
  <br>
  <p>
    In 1930 and 1931, Kurt G&ouml;del published two results that now underlie the study of mathematical logic, or
    &ldquo;meta-mathematics&rdquo; in a sense. The Incompleteness Theorems state, in simplified terms: for any
    &ldquo;formal system,&rdquo; (1)
    so long as no statement can be proven both true and false, there are statements that cannot be proven nor disproven,
    making the system <em>incomplete</em>; and (2) it cannot be proven that the system is <em>consistent</em>&mdash;no
    statement is both true
    and false&mdash;within itself. Though the actual proof of these is rather complicated, and jargon tends to render
    discussions of them nearly incomprehensible, the implications of these theorems are staggering. They mean that as
    long as we avoid contradictions in math, a fundamental property of proofs, it is impossible to prove every possible
    result: there will always be things we do not know, some part of the field perpetually beyond our reach.
  </p>
  <p>
    G&ouml;del&rsquo;s Incompleteness Theorems could be construed to show that math itself is wrong. Indeed, many people
    have done
    so, calling G&ouml;del&rsquo;s notion &ldquo;math&rsquo;s fundamental flaw,&rdquo; a &ldquo;paradox at its
    heart.&rdquo; At the time of his writing, other
    mathematicians had begun to define &ldquo;formal systems&rdquo; of mathematics, identifying the
    axioms&mdash;fundamental statements
    assumed to be true&mdash;on which the discipline rests. These are models, but really they are models of a model, our
    system of notation and expression of mathematical concepts being itself one large model for the abstract nature of
    math. G&ouml;del has thus not demonstrated that math is wrong but that our model of it&mdash;along with any other
    model of it
    we could think to create&mdash;is wrong. Yet it must still be useful, or else we would not require children to spend
    twelve years learning it, nor build from it an entire academic discipline in which researchers cling to the hope of
    improving the tools and knowledge available to the rest of the world.
  </p>
  <br>
  <p>
    One of the most impactful books on my education&mdash;though I did not read it for school&mdash;is <em>Math on
      Trial</em>, in which
    mother-daughter author duo Leila Schneps and Coralie Colmez provide ten examples of &ldquo;how math is used and
    abused in
    the courtroom.&rdquo; Several involve models in some form, among these the case of Sylvia Ann Howland&rsquo;s death.
  </p>
  <p>
    In 1865, one specific instance of her signature was accused of being a forgery, and Benjamin Peirce, a Harvard
    mathematician, was summoned as an expert witness in the fraud case. In his testimony, he used the data from
    comparisons of 42 samples of Howland&rsquo;s signature to determine whether it was real or fake. He approximated the
    set
    of pairwise comparisons among this data with a statistical distribution that was close to the data he was given, but
    not identical, leading him to calculate the probability that two of her signatures, taken at random, would be
    exactly the same&mdash;as were the two on two pages of her will&mdash;as 1 in 931 quintillion, so microscopically
    small that the
    specimen he was presented with must have been a forgery. However, the model he constructed was flawed,
    overestimating the number of signatures that were very different and underestimating the number that were quite
    similar. This means that his approximation severely discounted the possibility of two signatures being exactly equal
    and made forgery seem like a much more likely outcome than it may actually have been.
  </p>
  <p>
    Peirce&rsquo;s model was nearly useless as evidence to his point because it missed the nuances of the
    situation&mdash;not only
    that the approximation diverged from the truth in a crucial part of the data, but also because he ignored the
    pragmatics, such as that two signatures written at the same desk with the same pen are rather likely to look nearly
    identical. This makes it wrong and, though the binomial distribution he used is valuable in many situations, not
    useful in a court of law. And there are many more examples, from 1865 to the present, of mathematical models being
    constructed in a way that misleads people, whether intentionally or unintentionally, usually involving statistics or
    probability as this case did. This can be done by ignoring (or simply failing to consider) information that would
    counter the claim the model seeks to make, as well as by omitting assumptions that have been made in order to
    support that claim. Though these presentations combine inaccuracy and inutility, that does not preclude Box&rsquo;s
    statement from being true overall: he said some, not all, models are useful.
  </p>
  <br>
  <p>
    In chemistry, a model simplifies an infinite number of possibilities down to a single value. In physics, a model
    attempts to describe the workings of the entire Universe with just eighteen particles. In math, a model draws a
    conclusion from incomplete information, while another shows that the whole system in which it exists is inherently
    incomplete. All of these point to the idea, which the last proves, that no model can be infallibly
    correct&mdash;there are
    holes in it somewhere. Yet, at the forefront of research in mathematics and in the natural sciences, experts all
    over the world use these models on a daily basis to study things as concrete as heat and energy and as abstract as
    mathematical logic. Even while other &ldquo;experts&rdquo; are using similar models to manipulate information, they
    demonstrate
    that some are incredibly useful in a wide range of applications despite their inevitable limitations. Therefore, it
    can be concluded that George Box may have oversimplified his claim, but his idea was accurate.
  </p>
  <p>
    This has implications for knowledge in all areas and for all knowers. Everything we know comes in models because our
    minds do not contain all of reality. Yuval Noah Harari, in his book <em>Sapiens</em>, thus extends Box&rsquo;s
    statement to all
    knowledge: &ldquo;The real test of &lsquo;knowledge&rsquo; is not whether it is true, but whether it empowers
    us.&hellip; [N]o theory is 100
    per cent correct. Consequently, truth is a poor test for knowledge. The real test is utility. A theory that enables
    us to do new things constitutes knowledge.&rdquo;
  </p>
</body>

<!-- link to doc: https://docs.google.com/document/d/1_WU7bfuybQdOhMqIQXStTh5rTZ8Mgg9G5i1skAMziAQ/ -->

</html>